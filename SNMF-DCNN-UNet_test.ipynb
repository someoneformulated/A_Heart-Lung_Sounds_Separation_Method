{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function：input:feature，out:its type\n",
    "#0：SR  1：MR  2：VB  3：VR  4：WR\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset  \n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import datasets\n",
    "import torch.utils.data as Data\n",
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "checked-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------FUNCTION OF IMPORT 2 DATASET----------------\n",
    "class lungDataset(Dataset):#此类继承自dataset\n",
    "    def __init__(self,inputs,sig_num,in_width,in_height):  #\n",
    "        xy1=np.loadtxt(open(inputs,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "        \n",
    "        x=np.zeros([sig_num,in_width,in_height]) \n",
    "        y=np.zeros([sig_num])\n",
    "        for i in range(sig_num):  \n",
    "            x[i,:,:]=xy1[in_height*i:in_height*(i+1),0:256].T\n",
    "            ###DATA\n",
    "            y[i]=xy1[in_height*i,256]#LABEL\n",
    "        \n",
    "        x=x.astype('float32') \n",
    "        y=y.astype('int64') \n",
    "        x=torch.from_numpy(x);y=torch.from_numpy(y)\n",
    "        x=x[:,np.newaxis,:,:]\n",
    "        x = Variable(x,requires_grad=True);\n",
    "#         x=x.cuda(0);y=y.cuda(0)\n",
    "        self.x_data = x\n",
    "        self.y_data = y\n",
    "        self.len = x.shape[0] \n",
    "        \n",
    "    def __getitem__(self, index):   \n",
    "        return self.x_data[index], self.y_data[index]\n",
    " \n",
    "    def __len__(self): #可返回数据条数\n",
    "        return self.len\n",
    "\n",
    "class myDataset(Dataset):#\n",
    "    def __init__(self,mix,m_h,sig_num,seq_len,input_size):\n",
    "        #路径由实例对象提供\n",
    "        #  x0:INPUT     x1:MASK OF HS   x2：MASK OF LS\n",
    "        x0=np.loadtxt(open(mix,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "        tempt=np.zeros([sig_num,seq_len,input_size]) \n",
    "        for i in range(sig_num):  \n",
    "            for hang in range(seq_len):\n",
    "                for lie in range(input_size):\n",
    "                    tempt[i,hang,lie]=x0[hang+i*seq_len,lie]\n",
    "        x0=tempt.astype('float32')\n",
    "        \n",
    "        x1=np.loadtxt(open(m_h,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "        tempt=np.zeros([sig_num,seq_len,input_size]) \n",
    "        for i in range(sig_num):  \n",
    "            for hang in range(seq_len):\n",
    "                for lie in range(input_size):\n",
    "                    tempt[i,hang,lie]=x1[hang+i*seq_len,lie]\n",
    "        x1=tempt.astype('float32')    \n",
    "        \n",
    "        x0=torch.from_numpy(x0);x1=torch.from_numpy(x1);\n",
    "\n",
    "        x0=Variable(x0,requires_grad=True);x1=Variable(x1,requires_grad=True);\n",
    "        \n",
    "        x0=x0[:,np.newaxis,:,:];x1=x1[:,np.newaxis,:,:];\n",
    "        x0.cuda(0);x1.cuda(0);\n",
    "\n",
    "        self.len = x0.shape[0] # shape\n",
    "        self.x0_data=x0;self.x1_data=x1;\n",
    "        \n",
    "   \n",
    "    def __getitem__(self, index):    \n",
    "        \n",
    "        return self.x0_data[index].cuda(0),self.x1_data[index].cuda(0)\n",
    "    \n",
    "    def __len__(self): #\n",
    "        return self.len\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "measured-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------2 MODELS----------------------\n",
    "class MyDCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDCNN, self).__init__()\n",
    "        self.pooling1=torch.nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        self.cnn10=nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,\n",
    "                              stride=1,padding=1,bias=False, dilation=2)\n",
    "    \n",
    "        self.cnn20=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,\n",
    "                              stride=1,padding=1,bias=False, dilation=2)\n",
    "\n",
    "        self.cnn30=nn.Conv2d(in_channels=32,out_channels=48,kernel_size=3,\n",
    "                        stride=1,padding=1,bias=False, dilation=2)\n",
    "        \n",
    "        self.cnn40=nn.Conv2d(in_channels=48,out_channels=64,kernel_size=3,\n",
    "                        stride=1,padding=1,bias=False, dilation=2)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.fc1=torch.nn.Linear(5376,128)\n",
    "        self.fc2=torch.nn.Linear(128,64)\n",
    "        self.fc3=torch.nn.Linear(64,8)\n",
    "    def forward(self,x):\n",
    "        batch_size=x.size(0)\n",
    "        en=nn.functional.elu(x, alpha=1.0, inplace=False)\n",
    "        en=torch.relu(self.cnn10(en))\n",
    "        en =self.pooling1(en)##############    \n",
    "        en=torch.relu(self.cnn20(en))\n",
    "        en =self.pooling1(en)##############\n",
    "        en=torch.relu(self.cnn30(en))\n",
    "        en =self.pooling1(en)##############\n",
    "        en=torch.relu(self.cnn40(en))\n",
    "        en=self.bn4(en)\n",
    "        en =self.pooling1(en)##############\n",
    "        en=en.view(batch_size,-1)\n",
    "        en=self.fc1(en)\n",
    "        en=self.fc2(en)\n",
    "        en=self.fc3(en)\n",
    "        return en\n",
    "   \n",
    "\n",
    "class MyUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #CODING（3+1）\n",
    "        self.bn1= nn.BatchNorm2d(48);self.bn2= nn.BatchNorm2d(96);self.bn3= nn.BatchNorm2d(144);\n",
    "        self.bn0= nn.BatchNorm2d(1);\n",
    "        self.encode1_1 =nn.Conv2d(1,48,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode1_2=nn.Conv2d(48,48,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode2_1=nn.Conv2d(48,96,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode2_2=nn.Conv2d(96,96,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode3_1=nn.Conv2d(96,144,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode3_2=nn.Conv2d(144,144,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode4_1=nn.Conv2d(144,144,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.encode4_2=nn.Conv2d(144,144,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        #DECODING（3+1）\n",
    "        self.upsample3= nn.ConvTranspose2d(144,144,kernel_size=2,stride=2,padding=0);                                       \n",
    "        self.decode3_1 =nn.Conv2d(288,144,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.decode3_2 =nn.Conv2d(144,144,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.upsample2= nn.ConvTranspose2d(144,144,kernel_size=2,stride=2,padding=0);\n",
    "        self.decode2_1 =nn.Conv2d(240,96,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.decode2_2 =nn.Conv2d(96,96,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.upsample1= nn.ConvTranspose2d(96,96,kernel_size=2,stride=2,padding=0);\n",
    "        self.decode1_1 =nn.Conv2d(144,48,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.decode1_2 =nn.Conv2d(48,48,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.decode0=nn.Conv2d(48,1,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "    def forward(self,x):\n",
    "        enc1 = torch.relu(self.encode1_1(x))\n",
    "        enc1 = torch.relu(self.encode1_2(enc1))\n",
    "        enc1 =self.bn1(enc1)\n",
    "        enc2 = F.max_pool2d(enc1, kernel_size=2, stride=2, padding=0)\n",
    "        enc2 = torch.relu(self.encode2_1(enc2))\n",
    "        enc2 = torch.relu(self.encode2_2(enc2))\n",
    "        enc2 =self.bn2(enc2)\n",
    "        enc3 = F.max_pool2d(enc2, kernel_size=2, stride=2, padding=0)\n",
    "        enc3 = torch.relu(self.encode3_1(enc3))\n",
    "        enc3 = torch.relu(self.encode3_2(enc3))\n",
    "        enc3 =self.bn3(enc3)\n",
    "        enc4 = F.max_pool2d(enc3, kernel_size=2, stride=2, padding=0)       \n",
    "        enc4 = torch.relu(self.encode4_1(enc4))\n",
    "        enc4 = torch.relu(self.encode4_2(enc4))\n",
    "        enc4 =self.bn3(enc4)\n",
    "        #解码部分\n",
    "        dec = self.upsample3(enc4)\n",
    "        dec = torch.relu(self.decode3_1(torch.cat([enc3,dec],dim=1)))\n",
    "        dec = torch.relu(self.decode3_2(dec))\n",
    "        dec =self.bn3(dec)\n",
    "        dec = self.upsample2(dec)\n",
    "        dec = torch.relu(self.decode2_1(torch.cat([enc2,dec],dim=1)))\n",
    "        dec = torch.relu(self.decode2_2(dec))\n",
    "        dec =self.bn2(dec)\n",
    "        dec = self.upsample1(dec)\n",
    "        dec = torch.relu(self.decode1_1(torch.cat([enc1,dec],dim=1)))\n",
    "        dec = torch.relu(self.decode1_2(dec))\n",
    "        dec =self.bn1(dec)\n",
    "        out = self.bn0(torch.tanh(self.decode0(dec)))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stunning-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyUnet(\n",
       "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encode1_1): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode1_2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode2_1): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode2_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode3_1): Conv2d(96, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode3_2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode4_1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (encode4_2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (upsample3): ConvTranspose2d(144, 144, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decode3_1): Conv2d(288, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (decode3_2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (upsample2): ConvTranspose2d(144, 144, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decode2_1): Conv2d(240, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (decode2_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (upsample1): ConvTranspose2d(96, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (decode1_1): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (decode1_2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (decode0): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------LOAD MODEL---------------\n",
    "m_state_dict = torch.load('my_dcnn.pt')  #LOAD PARAS\n",
    "new_m = MyDCNN()              \n",
    "new_m.load_state_dict(m_state_dict) \n",
    "\n",
    "m_state_dict = torch.load('my_unet_0鼾声.pt')  \n",
    "new_u =MyUnet()             \n",
    "new_u.load_state_dict(m_state_dict) \n",
    "new_u.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测分类 tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "真实分类 tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "[1.0]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#--------------INPUT DCNN FEATURE-------------------\n",
    "acc_all=[]\n",
    "in_width=256\n",
    "in_height=128\n",
    "sig_num=250\n",
    "dataset=lungDataset(inputs=\"C:\\\\Users\\\\HS\\\\Desktop\\\\DC+U\\\\测试数据\\\\dcnn_ltf_250_2肺泡呼吸音.csv\",\n",
    "                    sig_num=sig_num,in_width=in_width,\n",
    "                    in_height=in_height)\n",
    "dcnn_validation_loader=DataLoader(dataset=dataset,batch_size=sig_num,shuffle=False,num_workers=0)\n",
    "\n",
    "# dataset=lungDataset(inputs=\"C:\\\\Users\\\\HS\\\\Desktop\\\\分类肺音\\\\DCNN训练数据_2240肺音分类时频矩阵.csv\",\n",
    "#                     sig_num=sig_num,in_width=in_width,\n",
    "#                     in_height=in_height)\n",
    "# dcnn_validation_loader=DataLoader(dataset=dataset,batch_size=sig_num,shuffle=True,num_workers=0)\n",
    "\n",
    "#-----------DCNN------------\n",
    "for step,(x,y) in enumerate(dcnn_validation_loader):\n",
    "    train_corrects=0\n",
    "    output_test=new_m(x)\n",
    "    pre_lab=torch.argmax(output_test,1)\n",
    "    print('预测分类',pre_lab);print('真实分类',y)\n",
    "    corrects=torch.sum(pre_lab == y.data) #ACC pre_lab == b_y.data\n",
    "    num=x.size(0) #\n",
    "    acc_all.append(corrects.double().item()/num)\n",
    "    print(acc_all)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-madness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "narrative-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第  1个信号的loss: 428.17\n",
      "第  2个信号的loss: 1111.42\n",
      "第  3个信号的loss: 421.05\n",
      "第  4个信号的loss: 476.24\n",
      "第  5个信号的loss: 325.42\n",
      "第  6个信号的loss: 614.00\n",
      "第  7个信号的loss: 176.94\n",
      "第  8个信号的loss: 221.32\n",
      "第  9个信号的loss: 484.40\n",
      "第 10个信号的loss: 917.24\n",
      "第 11个信号的loss: 339.54\n",
      "第 12个信号的loss: 262.80\n",
      "第 13个信号的loss: 321.26\n",
      "第 14个信号的loss: 684.62\n",
      "第 15个信号的loss: 444.37\n",
      "第 16个信号的loss: 306.14\n",
      "第 17个信号的loss: 281.38\n",
      "第 18个信号的loss: 228.60\n",
      "第 19个信号的loss: 949.51\n",
      "第 20个信号的loss: 885.14\n",
      "第 21个信号的loss: 542.04\n",
      "第 22个信号的loss: 1018.69\n",
      "第 23个信号的loss: 283.06\n",
      "第 24个信号的loss: 552.12\n",
      "第 25个信号的loss: 405.07\n",
      "第 26个信号的loss: 486.73\n",
      "第 27个信号的loss: 206.32\n",
      "第 28个信号的loss: 276.89\n",
      "第 29个信号的loss: 599.57\n",
      "第 30个信号的loss: 400.67\n",
      "第 31个信号的loss: 3270.92\n",
      "第 32个信号的loss: 310.12\n",
      "第 33个信号的loss: 445.86\n",
      "第 34个信号的loss: 585.93\n",
      "第 35个信号的loss: 274.19\n",
      "第 36个信号的loss: 195.52\n",
      "第 37个信号的loss: 240.02\n",
      "第 38个信号的loss: 240.18\n",
      "第 39个信号的loss: 467.29\n",
      "第 40个信号的loss: 225.69\n",
      "第 41个信号的loss: 2974.68\n",
      "第 42个信号的loss: 300.00\n",
      "第 43个信号的loss: 486.58\n",
      "第 44个信号的loss: 1445.80\n",
      "第 45个信号的loss: 453.81\n",
      "第 46个信号的loss: 414.59\n",
      "第 47个信号的loss: 3038.27\n",
      "第 48个信号的loss: 1129.31\n",
      "第 49个信号的loss: 966.55\n",
      "第 50个信号的loss: 566.67\n",
      "第 51个信号的loss: 32.22\n",
      "第 52个信号的loss: 200.69\n",
      "第 53个信号的loss: 45.42\n",
      "第 54个信号的loss: 75.11\n",
      "第 55个信号的loss: 29.60\n",
      "第 56个信号的loss: 100.46\n",
      "第 57个信号的loss: 19.48\n",
      "第 58个信号的loss: 40.89\n",
      "第 59个信号的loss: 35.28\n",
      "第 60个信号的loss: 154.17\n",
      "第 61个信号的loss: 29.94\n",
      "第 62个信号的loss: 36.57\n",
      "第 63个信号的loss: 35.37\n",
      "第 64个信号的loss: 100.58\n",
      "第 65个信号的loss: 97.94\n",
      "第 66个信号的loss: 29.03\n",
      "第 67个信号的loss: 36.16\n",
      "第 68个信号的loss: 33.27\n",
      "第 69个信号的loss: 136.33\n",
      "第 70个信号的loss: 171.40\n",
      "第 71个信号的loss: 90.74\n",
      "第 72个信号的loss: 134.71\n",
      "第 73个信号的loss: 30.06\n",
      "第 74个信号的loss: 92.72\n",
      "第 75个信号的loss: 39.56\n",
      "第 76个信号的loss: 91.82\n",
      "第 77个信号的loss: 39.20\n",
      "第 78个信号的loss: 20.14\n",
      "第 79个信号的loss: 47.08\n",
      "第 80个信号的loss: 38.78\n",
      "第 81个信号的loss: 344.61\n",
      "第 82个信号的loss: 32.64\n",
      "第 83个信号的loss: 46.45\n",
      "第 84个信号的loss: 78.94\n",
      "第 85个信号的loss: 32.44\n",
      "第 86个信号的loss: 35.14\n",
      "第 87个信号的loss: 37.31\n",
      "第 88个信号的loss: 42.60\n",
      "第 89个信号的loss: 43.11\n",
      "第 90个信号的loss: 34.07\n",
      "第 91个信号的loss: 375.84\n",
      "第 92个信号的loss: 37.93\n",
      "第 93个信号的loss: 39.59\n",
      "第 94个信号的loss: 197.03\n",
      "第 95个信号的loss: 82.37\n",
      "第 96个信号的loss: 35.36\n",
      "第 97个信号的loss: 330.65\n",
      "第 98个信号的loss: 195.11\n",
      "第 99个信号的loss: 212.40\n",
      "第100个信号的loss: 114.62\n",
      "第101个信号的loss: 78.12\n",
      "第102个信号的loss: 167.08\n",
      "第103个信号的loss: 66.78\n",
      "第104个信号的loss: 122.60\n",
      "第105个信号的loss: 63.31\n",
      "第106个信号的loss: 130.77\n",
      "第107个信号的loss: 47.05\n",
      "第108个信号的loss: 89.43\n",
      "第109个信号的loss: 100.84\n",
      "第110个信号的loss: 208.47\n",
      "第111个信号的loss: 76.52\n",
      "第112个信号的loss: 58.54\n",
      "第113个信号的loss: 87.97\n",
      "第114个信号的loss: 121.75\n",
      "第115个信号的loss: 124.14\n",
      "第116个信号的loss: 62.38\n",
      "第117个信号的loss: 74.05\n",
      "第118个信号的loss: 52.39\n",
      "第119个信号的loss: 223.67\n",
      "第120个信号的loss: 311.26\n",
      "第121个信号的loss: 155.86\n",
      "第122个信号的loss: 241.37\n",
      "第123个信号的loss: 42.04\n",
      "第124个信号的loss: 132.29\n",
      "第125个信号的loss: 89.21\n",
      "第126个信号的loss: 131.01\n",
      "第127个信号的loss: 65.10\n",
      "第128个信号的loss: 55.69\n",
      "第129个信号的loss: 106.55\n",
      "第130个信号的loss: 79.67\n",
      "第131个信号的loss: 687.11\n",
      "第132个信号的loss: 68.89\n",
      "第133个信号的loss: 95.76\n",
      "第134个信号的loss: 114.62\n",
      "第135个信号的loss: 78.44\n",
      "第136个信号的loss: 56.91\n",
      "第137个信号的loss: 61.64\n",
      "第138个信号的loss: 64.40\n",
      "第139个信号的loss: 93.62\n",
      "第140个信号的loss: 53.08\n",
      "第141个信号的loss: 729.43\n",
      "第142个信号的loss: 78.47\n",
      "第143个信号的loss: 85.22\n",
      "第144个信号的loss: 140.32\n",
      "第145个信号的loss: 157.99\n",
      "第146个信号的loss: 83.56\n",
      "第147个信号的loss: 831.89\n",
      "第148个信号的loss: 178.11\n",
      "第149个信号的loss: 149.01\n",
      "第150个信号的loss: 128.05\n",
      "第151个信号的loss: 31.02\n",
      "第152个信号的loss: 56.60\n",
      "第153个信号的loss: 51.02\n",
      "第154个信号的loss: 84.80\n",
      "第155个信号的loss: 26.31\n",
      "第156个信号的loss: 26.26\n",
      "第157个信号的loss: 22.34\n",
      "第158个信号的loss: 39.59\n",
      "第159个信号的loss: 32.01\n",
      "第160个信号的loss: 112.60\n",
      "第161个信号的loss: 21.12\n",
      "第162个信号的loss: 38.58\n",
      "第163个信号的loss: 28.82\n",
      "第164个信号的loss: 30.24\n",
      "第165个信号的loss: 32.42\n",
      "第166个信号的loss: 25.43\n",
      "第167个信号的loss: 38.69\n",
      "第168个信号的loss: 37.04\n",
      "第169个信号的loss: 124.59\n",
      "第170个信号的loss: 242.37\n",
      "第171个信号的loss: 88.10\n",
      "第172个信号的loss: 125.59\n",
      "第173个信号的loss: 16.14\n",
      "第174个信号的loss: 77.27\n",
      "第175个信号的loss: 21.23\n",
      "第176个信号的loss: 87.85\n",
      "第177个信号的loss: 37.44\n",
      "第178个信号的loss: 20.25\n",
      "第179个信号的loss: 25.64\n",
      "第180个信号的loss: 25.03\n",
      "第181个信号的loss: 342.37\n",
      "第182个信号的loss: 19.11\n",
      "第183个信号的loss: 23.72\n",
      "第184个信号的loss: 17.63\n",
      "第185个信号的loss: 19.28\n",
      "第186个信号的loss: 37.69\n",
      "第187个信号的loss: 26.52\n",
      "第188个信号的loss: 40.07\n",
      "第189个信号的loss: 24.04\n",
      "第190个信号的loss: 43.50\n",
      "第191个信号的loss: 390.87\n",
      "第192个信号的loss: 28.88\n",
      "第193个信号的loss: 22.80\n",
      "第194个信号的loss: 61.14\n",
      "第195个信号的loss: 33.01\n",
      "第196个信号的loss: 25.02\n",
      "第197个信号的loss: 332.80\n",
      "第198个信号的loss: 67.92\n",
      "第199个信号的loss: 79.73\n",
      "第200个信号的loss: 33.17\n",
      "第201个信号的loss: 132.82\n",
      "第202个信号的loss: 455.02\n",
      "第203个信号的loss: 163.94\n",
      "第204个信号的loss: 386.27\n",
      "第205个信号的loss: 152.86\n",
      "第206个信号的loss: 298.56\n",
      "第207个信号的loss: 98.46\n",
      "第208个信号的loss: 198.90\n",
      "第209个信号的loss: 196.55\n",
      "第210个信号的loss: 548.65\n",
      "第211个信号的loss: 143.77\n",
      "第212个信号的loss: 194.21\n",
      "第213个信号的loss: 175.49\n",
      "第214个信号的loss: 295.25\n",
      "第215个信号的loss: 279.42\n",
      "第216个信号的loss: 140.28\n",
      "第217个信号的loss: 128.10\n",
      "第218个信号的loss: 194.85\n",
      "第219个信号的loss: 605.91\n",
      "第220个信号的loss: 645.83\n",
      "第221个信号的loss: 445.21\n",
      "第222个信号的loss: 611.22\n",
      "第223个信号的loss: 122.54\n",
      "第224个信号的loss: 448.38\n",
      "第225个信号的loss: 151.57\n",
      "第226个信号的loss: 452.30\n",
      "第227个信号的loss: 177.38\n",
      "第228个信号的loss: 121.32\n",
      "第229个信号的loss: 187.55\n",
      "第230个信号的loss: 139.00\n",
      "第231个信号的loss: 1409.24\n",
      "第232个信号的loss: 143.24\n",
      "第233个信号的loss: 170.63\n",
      "第234个信号的loss: 254.92\n",
      "第235个信号的loss: 148.36\n",
      "第236个信号的loss: 171.55\n",
      "第237个信号的loss: 129.24\n",
      "第238个信号的loss: 202.48\n",
      "第239个信号的loss: 152.42\n",
      "第240个信号的loss: 196.74\n",
      "第241个信号的loss: 1553.19\n",
      "第242个信号的loss: 158.39\n",
      "第243个信号的loss: 149.21\n",
      "第244个信号的loss: 456.41\n",
      "第245个信号的loss: 332.96\n",
      "第246个信号的loss: 145.57\n",
      "第247个信号的loss: 1449.57\n",
      "第248个信号的loss: 462.67\n",
      "第249个信号的loss: 452.94\n",
      "第250个信号的loss: 329.02\n",
      "第251个信号的loss: 185.91\n",
      "第252个信号的loss: 653.76\n",
      "第253个信号的loss: 369.75\n",
      "第254个信号的loss: 508.10\n",
      "第255个信号的loss: 194.27\n",
      "第256个信号的loss: 414.84\n",
      "第257个信号的loss: 112.76\n",
      "第258个信号的loss: 275.05\n",
      "第259个信号的loss: 242.41\n",
      "第260个信号的loss: 828.27\n",
      "第261个信号的loss: 188.20\n",
      "第262个信号的loss: 227.82\n",
      "第263个信号的loss: 206.14\n",
      "第264个信号的loss: 359.51\n",
      "第265个信号的loss: 388.36\n",
      "第266个信号的loss: 180.42\n",
      "第267个信号的loss: 159.73\n",
      "第268个信号的loss: 203.76\n",
      "第269个信号的loss: 812.78\n",
      "第270个信号的loss: 659.55\n",
      "第271个信号的loss: 595.89\n",
      "第272个信号的loss: 715.81\n",
      "第273个信号的loss: 155.54\n",
      "第274个信号的loss: 492.50\n",
      "第275个信号的loss: 217.69\n",
      "第276个信号的loss: 583.81\n",
      "第277个信号的loss: 233.74\n",
      "第278个信号的loss: 146.97\n",
      "第279个信号的loss: 263.10\n",
      "第280个信号的loss: 202.39\n",
      "第281个信号的loss: 1766.80\n",
      "第282个信号的loss: 172.64\n",
      "第283个信号的loss: 258.23\n",
      "第284个信号的loss: 299.87\n",
      "第285个信号的loss: 186.22\n",
      "第286个信号的loss: 252.06\n",
      "第287个信号的loss: 207.62\n",
      "第288个信号的loss: 216.97\n",
      "第289个信号的loss: 214.27\n",
      "第290个信号的loss: 210.22\n",
      "第291个信号的loss: 1806.68\n",
      "第292个信号的loss: 171.69\n",
      "第293个信号的loss: 203.56\n",
      "第294个信号的loss: 597.03\n",
      "第295个信号的loss: 385.39\n",
      "第296个信号的loss: 213.48\n",
      "第297个信号的loss: 1832.55\n",
      "第298个信号的loss: 625.35\n",
      "第299个信号的loss: 635.52\n",
      "第300个信号的loss: 467.72\n",
      "第301个信号的loss: 80.71\n",
      "第302个信号的loss: 276.17\n",
      "第303个信号的loss: 77.73\n",
      "第304个信号的loss: 139.30\n",
      "第305个信号的loss: 63.01\n",
      "第306个信号的loss: 168.13\n",
      "第307个信号的loss: 45.35\n",
      "第308个信号的loss: 67.50\n",
      "第309个信号的loss: 94.24\n",
      "第310个信号的loss: 285.57\n",
      "第311个信号的loss: 82.57\n",
      "第312个信号的loss: 66.38\n",
      "第313个信号的loss: 77.72\n",
      "第314个信号的loss: 143.11\n",
      "第315个信号的loss: 134.41\n",
      "第316个信号的loss: 60.64\n",
      "第317个信号的loss: 70.39\n",
      "第318个信号的loss: 62.32\n",
      "第319个信号的loss: 257.85\n",
      "第320个信号的loss: 288.76\n",
      "第321个信号的loss: 152.97\n",
      "第322个信号的loss: 272.19\n",
      "第323个信号的loss: 60.86\n",
      "第324个信号的loss: 146.08\n",
      "第325个信号的loss: 93.61\n",
      "第326个信号的loss: 159.28\n",
      "第327个信号的loss: 64.17\n",
      "第328个信号的loss: 48.24\n",
      "第329个信号的loss: 99.74\n",
      "第330个信号的loss: 89.85\n",
      "第331个信号的loss: 733.67\n",
      "第332个信号的loss: 76.54\n",
      "第333个信号的loss: 94.56\n",
      "第334个信号的loss: 170.78\n",
      "第335个信号的loss: 70.12\n",
      "第336个信号的loss: 63.88\n",
      "第337个信号的loss: 75.81\n",
      "第338个信号的loss: 71.74\n",
      "第339个信号的loss: 93.21\n",
      "第340个信号的loss: 62.22\n",
      "第341个信号的loss: 701.77\n",
      "第342个信号的loss: 76.32\n",
      "第343个信号的loss: 81.42\n",
      "第344个信号的loss: 290.63\n",
      "第345个信号的loss: 151.40\n",
      "第346个信号的loss: 91.36\n",
      "第347个信号的loss: 753.06\n",
      "第348个信号的loss: 187.28\n",
      "第349个信号的loss: 266.07\n",
      "第350个信号的loss: 123.35\n",
      "第351个信号的loss: 447.66\n",
      "第352个信号的loss: 1476.37\n",
      "第353个信号的loss: 758.80\n",
      "第354个信号的loss: 546.94\n",
      "第355个信号的loss: 395.11\n",
      "第356个信号的loss: 960.59\n",
      "第357个信号的loss: 251.78\n",
      "第358个信号的loss: 263.81\n",
      "第359个信号的loss: 566.22\n",
      "第360个信号的loss: 1416.27\n",
      "第361个信号的loss: 308.68\n",
      "第362个信号的loss: 274.72\n",
      "第363个信号的loss: 370.55\n",
      "第364个信号的loss: 1002.79\n",
      "第365个信号的loss: 718.61\n",
      "第366个信号的loss: 315.81\n",
      "第367个信号的loss: 316.45\n",
      "第368个信号的loss: 240.97\n",
      "第369个信号的loss: 1383.46\n",
      "第370个信号的loss: 1009.71\n",
      "第371个信号的loss: 678.08\n",
      "第372个信号的loss: 1469.21\n",
      "第373个信号的loss: 374.66\n",
      "第374个信号的loss: 662.81\n",
      "第375个信号的loss: 545.64\n",
      "第376个信号的loss: 517.72\n",
      "第377个信号的loss: 257.04\n",
      "第378个信号的loss: 306.37\n",
      "第379个信号的loss: 837.49\n",
      "第380个信号的loss: 469.16\n",
      "第381个信号的loss: 3698.35\n",
      "第382个信号的loss: 398.51\n",
      "第383个信号的loss: 559.97\n",
      "第384个信号的loss: 708.37\n",
      "第385个信号的loss: 348.71\n",
      "第386个信号的loss: 272.42\n",
      "第387个信号的loss: 377.16\n",
      "第388个信号的loss: 234.18\n",
      "第389个信号的loss: 514.87\n",
      "第390个信号的loss: 248.32\n",
      "第391个信号的loss: 3585.60\n",
      "第392个信号的loss: 372.28\n",
      "第393个信号的loss: 588.40\n",
      "第394个信号的loss: 1268.29\n",
      "第395个信号的loss: 794.38\n",
      "第396个信号的loss: 419.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第397个信号的loss: 3785.19\n",
      "第398个信号的loss: 1431.33\n",
      "第399个信号的loss: 1615.74\n",
      "第400个信号的loss: 954.14\n"
     ]
    }
   ],
   "source": [
    "##-------------定义损失函数-----------------\n",
    "class My_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,out_pred,mix,m_h):\n",
    "        lossh = mix* (out_pred - m_h)           #[[B, C, H, W]]\n",
    "        loss=torch.sum(torch.sum(torch.pow(lossh, 2), 1))\n",
    "        return loss\n",
    "criterion = My_loss()\n",
    "#--------------unet-------------------\n",
    "seq_len=256         \n",
    "input_size=128      \n",
    "sig_num=400\n",
    "dataset=myDataset(mix=\"C:\\\\Users\\\\HS\\\\Desktop\\\\DC+U\\\\测试数据\\\\unet_mix_400_4哮鸣音.csv\",\n",
    "                  m_h=\"C:\\\\Users\\\\HS\\\\Desktop\\\\DC+U\\\\测试数据\\\\unet_m_h_400_4哮鸣音.csv\",\n",
    "                  sig_num=sig_num,seq_len=seq_len,input_size=input_size)\n",
    "unet_valid_loader = DataLoader(dataset=dataset, batch_size=1, shuffle=False,num_workers=0) \n",
    "    \n",
    "#-----------unet------------ \n",
    "for index, (mix,m_h) in enumerate(unet_valid_loader,0):\n",
    "    if pre_lab.data[index]==0:\n",
    "        m_state_dict = torch.load('my_unet0_鼾声.pt')  \n",
    "    if pre_lab.data[index]==1:\n",
    "        m_state_dict = torch.load('my_unet01_湿罗音.pt')   \n",
    "    if pre_lab.data[index]==2:\n",
    "        m_state_dict = torch.load('my_unet2_肺泡呼吸音.pt')  \n",
    "    if pre_lab.data[index]==3:\n",
    "        m_state_dict = torch.load('my_unet3_支气管呼吸音.pt')   \n",
    "    if pre_lab.data[index]==4:\n",
    "        m_state_dict = torch.load('my_unet4_哮鸣音.pt')    \n",
    "\n",
    "    new_u =MyUnet()              \n",
    "    new_u.load_state_dict(m_state_dict) \n",
    "    new_u.cuda()\n",
    "    \n",
    "    out_pred=new_u(mix)\n",
    "    loss = criterion(out_pred,mix,m_h)\n",
    "    print('第{:3d}个信号的loss: {:5.2f}'.format(index+1,loss))\n",
    "    # -----------------PREDICT MASK-------------\n",
    "    out_h=out_pred;out_l=1-out_pred\n",
    "    h_mask=torch.reshape(out_h,(256,128));l_mask=torch.reshape(out_l,(256,128))\n",
    "\n",
    "    h_mask=h_mask.cpu();l_mask=l_mask.cpu()\n",
    "    h_mask=h_mask.detach().numpy();l_mask=l_mask.detach().numpy()\n",
    "    np.savetxt('C:\\\\Users\\\\HS\\Desktop\\\\DC+U\\\\unet生成数据\\\\400_4哮鸣音h_mask%d.csv'%(index+1), h_mask, delimiter = ',')\n",
    "    np.savetxt('C:\\\\Users\\\\HS\\\\Desktop\\\\DC+U\\\\unet生成数据\\\\400_4哮鸣音l_mask%d.csv'%(index+1), l_mask, delimiter = ',')\n",
    "#     print(h_mask.shape);print(l_mask.shape)\n",
    "    # -----------------OUTPUT :MASKS OF HS AND LS-------------\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-episode",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-winter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-bennett",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
